{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model in Edward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import edward as ed\n",
    "import tensorflow as tf\n",
    "from edward.models import Dirichlet, InverseGamma, Normal, ParamMixture, Empirical, Categorical\n",
    "\n",
    "from utils import SEED, generate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_datasets(filename='gmm_6k.pkl', n=3):\n",
    "  \"\"\"\n",
    "  :param filename: name of the pickle file \n",
    "  :param n: number of datasets to read (defults to 3)\n",
    "  :return: list of loaded datasets in dict format\n",
    "  \"\"\"\n",
    "  datasets = []\n",
    "  with open(filename, 'rb') as f:\n",
    "    for i in range(n):\n",
    "      dataset = pickle.load(f)\n",
    "      datasets.append(dataset)      \n",
    "  return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model\n",
    "\n",
    "Adapted from [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edward_model(K, N):\n",
    "  w_e = Dirichlet(tf.ones(K))\n",
    "  mu_e = Normal(tf.zeros(1), tf.ones(1)*10, sample_shape=K)\n",
    "  sigmasq_e = InverseGamma(tf.ones(1), tf.ones(1), sample_shape=K)\n",
    "  y_e = ParamMixture(w_e, {'loc': mu_e, 'scale_diag': tf.sqrt(sigmasq_e)},\n",
    "                   MultivariateNormalDiag,\n",
    "                   sample_shape=N)\n",
    "  z_e = y_e.cat\n",
    "  \n",
    "  return w_e, mu_e, sigmasq_e, y_e, z_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ed_Gibbs(K, N, y, iters=20000, burn=8000, thin=10):\n",
    "  w_e, mu_e, sigmasq_e, y_e, z_e = edward_model(K, N)\n",
    "  \n",
    "  with tf.variable_scope('qw', reuse=tf.AUTO_REUSE):\n",
    "    qw = Empirical(tf.get_variable(\n",
    "        \"qw/params\", [iters, K],\n",
    "        initializer=tf.constant_initializer(1.0 / K)))\n",
    "  with tf.variable_scope('qmu', reuse=tf.AUTO_REUSE):\n",
    "    qmu = Empirical(tf.get_variable(\n",
    "        \"qmu/params\", [iters, K, 1],\n",
    "        initializer=tf.zeros_initializer()))\n",
    "  with tf.variable_scope('qsigmasq', reuse=tf.AUTO_REUSE):  \n",
    "    qsigmasq = Empirical(tf.get_variable(\n",
    "        \"qsigmasq/params\", [iters, K, 1],\n",
    "        initializer=tf.ones_initializer()))\n",
    "  with tf.variable_scope('qz', reuse=tf.AUTO_REUSE): \n",
    "    qz = Empirical(tf.get_variable(\n",
    "        \"qz/params\", [iters, N],\n",
    "        initializer=tf.zeros_initializer(),\n",
    "        dtype=tf.int32))\n",
    "\n",
    "  inference = ed.Gibbs({w_e: qw, mu_e: qmu, sigmasq_e: qsigmasq, z_e: qz},\n",
    "                     data={y_e: y[:,None]})\n",
    "  \n",
    "  sess = ed.get_session()\n",
    "  tf.global_variables_initializer().run()\n",
    "  \n",
    "  start = timer()\n",
    "  inference.run()\n",
    "  end = timer() \n",
    "  \n",
    "  return qw.params.eval()[burn:][::thin], qmu.params.eval()[burn:][::thin], \\\n",
    "    qsigmasq.params.eval()[burn:][::thin], qz.params.eval()[burn:][::thin], end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ed_Gibbs(filename='gmm_6k.pkl', n=3, iters=20000, burn=8000, thin=10):\n",
    "  \"\"\"\n",
    "  Runs Edward Gibbs algorithm.\n",
    "  Default 20000 iterations, 8000 burn in, 10 thin, big dataset (6 components)\n",
    "  Pass gmm_3k.pkl for small.\n",
    "  \"\"\"\n",
    "  datasets = load_datasets(filename, n)\n",
    "  \n",
    "  for dataset in datasets:\n",
    "    qw, qmu, qsigmasq, qz, time = _ed_Gibbs(dataset['K'], dataset['N'], dataset['y'], iters=iters, burn=burn, thin=thin)\n",
    "    \n",
    "    results = {'w': qw, 'mu':qmu, 'sigmasq': qsigmasq, 'z': qz, 'time': time, 'iters': iters, 'warmup': burn, 'thin': thin}\n",
    "    with open('results/edward/gibbs_{}k_{}.pkl'.format(dataset['K'], dataset['seed']), 'wb') as f:\n",
    "      pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed_Gibbs(filename='gmm_3k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_Gibbs(filename='gmm_6k.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Edward Tutorials: [Unupervised Learning](http://edwardlib.org/tutorials/unsupervised)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
