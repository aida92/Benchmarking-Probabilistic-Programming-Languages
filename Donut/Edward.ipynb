{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donut in Edward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "import edward as ed\n",
    "from edward.models import HalfNormal, Normal, Empirical\n",
    "\n",
    "from utils import generate_datasets, SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ed.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Edward_model(n_samples, n_dim):\n",
    "  R_e = HalfNormal(10.0)\n",
    "  r_e = HalfNormal(10.0)\n",
    "  C_e = Normal(0.0, 10.0, sample_shape = n_dim)\n",
    "  v_e = Normal(0.0, 1.0, sample_shape = [n_samples, n_dim])\n",
    "    \n",
    "  y_e = Normal(loc = C_e + R_e*v_e/tf.norm(v_e, axis=1, keepdims=True), scale=r_e)\n",
    "  return R_e, r_e, C_e, v_e, y_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _Ed_MH(y, n_samples, n_dim, iters=8000, burn=4000):\n",
    "  \"\"\"\n",
    "  Runs Edward's Metropolis-Hastings algorithm for one seed\n",
    "  \"\"\"\n",
    "  R_e, r_e, C_e, v_e, y_e = Edward_model(n_samples, n_dim)\n",
    "    \n",
    "  qR = Empirical(params=tf.Variable(tf.ones(iters) * .5))\n",
    "  qr = Empirical(params=tf.Variable(tf.ones(iters) * .5))\n",
    "  qC = Empirical(params=tf.Variable(tf.ones([iters,n_dim]) * .5))\n",
    "\n",
    "  R_proposal = Normal(loc=R_e, scale=0.1)\n",
    "  r_proposal = Normal(loc=r_e, scale=0.1)\n",
    "  C_proposal = Normal(loc=C_e, scale=0.1)\n",
    "\n",
    "  inference = ed.MetropolisHastings({R_e: qR, r_e: qr, C_e: qC}, \n",
    "                                    {R_e: R_proposal, r_e: r_proposal, C_e: C_proposal}, data={y_e: y})\n",
    "    \n",
    "  start = timer()\n",
    "  inference.run()\n",
    "  end = timer()\n",
    "    \n",
    "  return qR.params.eval()[burn:], qr.params.eval()[burn:], qC.params.eval()[burn:], end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metropolis-Hastings\n",
    "def Ed_MH(n_samples, n_dim, iters=8000, burn=4000, seeds=SEED):\n",
    "  \"\"\"\n",
    "  Runs Edward's Metropolis-Hastings algorithm for each seed\n",
    "  \"\"\"\n",
    "  Y, C, R, r = generate_datasets(n_samples, n_dim, seeds)\n",
    "  results = {}\n",
    "  for seed,y in zip(seeds, Y):\n",
    "    qR, qr, qC, time = _Ed_MH(y, n_samples, n_dim, iters, burn)\n",
    "    results = {'time': time, 'R': qR, 'r': qr, 'C': qC, 'iters': iters, 'burn': burn}\n",
    "    with open('results/edward/mh_{}d_{}.pkl'.format(n_dim, seed), 'wb') as f:\n",
    "      pickle.dump(results, f)\n",
    "  print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small dataset\n",
    "n_samples = 1000\n",
    "n_dim = 2\n",
    "Ed_MH(n_samples, n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big dataset\n",
    "n_samples = 5000\n",
    "n_dim = 5\n",
    "Ed_MH(n_samples, n_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _Ed_VI(y, n_samples, n_dim, iters):\n",
    "  \"\"\"\n",
    "  Runs Edward's KLqp algorithm, for one seed \n",
    "  \"\"\"\n",
    "  R_e, r_e, C_e, v_e, y_e = Edward_model(n_samples, n_dim)\n",
    "    \n",
    "  with tf.variable_scope('qR', reuse=tf.AUTO_REUSE):\n",
    "    qR = HalfNormal(tf.nn.softplus(tf.get_variable('scale', [])))\n",
    "    \n",
    "  with tf.variable_scope('qr', reuse=tf.AUTO_REUSE):\n",
    "    qr = HalfNormal(tf.nn.softplus(tf.get_variable('scale', [])))\n",
    "\n",
    "  with tf.variable_scope('qC', reuse=tf.AUTO_REUSE):\n",
    "    qC = Normal(tf.get_variable('loc', [n_dim]),\n",
    "                      tf.nn.softplus(tf.get_variable('scale', [n_dim])))\n",
    "\n",
    "  inference = ed.KLqp({R_e: qR, r_e: qr, C_e: qC}, data={y_e: y})\n",
    "    \n",
    "  start = timer()\n",
    "  inference.run(n_samples=10, n_iter=iters)\n",
    "  end = timer()\n",
    "    \n",
    "  return qR, qr, qC, end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Ed_VI(n_samples, n_dim, seeds=SEED):\n",
    "  \"\"\"\n",
    "  Runs Edward's ADVI algorithm, for each seed \n",
    "  \"\"\"\n",
    "  Y, C, R, r = generate_datasets(n_samples, n_dim, seeds)\n",
    "  for y,seed in zip(Y, seeds):\n",
    "    print(seed)\n",
    "    iters = np.linspace(1000, 50000, 5).astype(int)\n",
    "    for n in iters:\n",
    "      qR, qr, qC, time = _Ed_VI(y, n_samples, n_dim, n)\n",
    "      print(time)\n",
    "      \n",
    "      results = {'time': time, 'iters': n, 'R': qR.sample(1000).eval()[:,None], 'r': qr.sample(1000).eval()[:,None], 'C': qC.sample(1000).eval()} \n",
    "      with open('results/edward/vi_{}d_{}.pkl'.format(n_dim, seed), 'ab') as f:\n",
    "        pickle.dump(results, f)\n",
    "  print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Small dataset\n",
    "n_samples = 1000\n",
    "n_dim = 2\n",
    "Ed_VI(n_samples, n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Big dataset\n",
    "n_samples = 5000\n",
    "n_dim = 5\n",
    "Ed_VI(n_samples, n_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
