{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Logistic Regression in PyMC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn.datasets as skd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "from utils import compute_metrics, SEED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data \n",
    "\n",
    "Credit Card Fraud Detection [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%gcs read --object \"gs://thesis-203306/data/creditcard.csv\" --variable csv_as_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(BytesIO(csv_as_bytes))\n",
    "\n",
    "df = df.drop('Time', 1)     # optional\n",
    "df['Amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def PyMC3_model(df):\n",
    "    model = pm.Model()\n",
    "    \n",
    "    with model:\n",
    "        pm.glm.GLM.from_formula('Class ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + Amount', df_train, \n",
    "                                family=pm.glm.families.Binomial())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pymc3_nuts(df, filename, seeds=SEED):\n",
    "  \"\"\"\n",
    "  Runs PyMC3 NUTS algorithm\n",
    "  Default: 1000 iterations (500 warmup)\n",
    "  Remark: Using default init (jitter+adapt_diag) can lead to bad initial values,\n",
    "  so we use only adapt_diag\n",
    "  \"\"\"\n",
    "  for seed in seeds:\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=seed) \n",
    "    pymc3_model = PyMC3_model(df_train)\n",
    "\n",
    "    with pymc3_model:\n",
    "      start = timer()\n",
    "      trace = pm.sample(n=500, tune=500, chains=2, seed=seed, init='adapt_diag')\n",
    "      end = timer()\n",
    "    \n",
    "    # Compute the scores\n",
    "    y_test = np.array(df_test.Class.tolist())     \n",
    "    df_test = df_test.drop('Class', 1)\n",
    "    X_test = np.array(df_test.values)\n",
    "    \n",
    "    w = []\n",
    "    for i in range(1,29):\n",
    "      param = 'V{}'.format(i)\n",
    "      w.append(np.array(trace.get_values(param,combine=False)).mean(axis=0))\n",
    "    w.append(np.array(trace.get_values('Amount',combine=False)).mean(axis=0))\n",
    "    \n",
    "    w = np.array(w)\n",
    "    w = w.T\n",
    "    b = np.array(trace.get_values('Intercept',combine=False)).mean(axis=0)\n",
    "\n",
    "    F1 = []\n",
    "    accuracy = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    for ww,bb in zip(w,b):\n",
    "      a, p, r, f = compute_metrics(ww,bb,X_test,y_test)\n",
    "      accuracy.append(a)\n",
    "      precision.append(p)\n",
    "      recall.append(r)\n",
    "      F1.append(f)\n",
    "\n",
    "    results = {'w': w, 'b': b, 'iters': 1000, 'warmup': 500, 'divergences': int(trace['diverging'].nonzero()[0].size),\n",
    "              'accuracy': accuracy, 'precision': precision, 'recall': recall, 'F1': F1, 'time': end-start} \n",
    "    \n",
    "    with open('results/pymc3/{}_{}_new.pkl'.format(filename, seed), 'wb') as f:\n",
    "      pickle.dump(results, f)\n",
    "    \n",
    "  print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Credit\n",
    "pymc3_nuts(df, 'nuts_credit', seeds=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pymc3_vi(df, filename, seeds=SEED):\n",
    "  \"\"\"\n",
    "  Runs PyMC3 ADVI algorithm\n",
    "  \"\"\"\n",
    "  for seed in seeds:\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    \n",
    "    y_test = np.array(df_test.Class.tolist()) \n",
    "    df_test = df_test.drop('Class', 1)\n",
    "    X_test = np.array(df_test.values)\n",
    "    \n",
    "    pymc3_model = PyMC3_model(df_train)\n",
    "    \n",
    "    F1 = []\n",
    "    accuracy = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    times = []\n",
    "    \n",
    "    iters = np.linspace(500, 10000, 5).astype(int)\n",
    "    for n in iters:\n",
    "      with pymc3_model:\n",
    "        start = timer()\n",
    "        advi_fit = pm.fit(n, random_seed=seed, callbacks=[pm.callbacks.CheckParametersConvergence(diff='absolute', tolerance=0.0001)])\n",
    "        end = timer()\n",
    "    \n",
    "      print('Sampling done')\n",
    "      times.append(end-start)\n",
    "\n",
    "      trace_advi = advi_fit.sample(draws=1000)\n",
    "      w = []\n",
    "      for i in range(1,29):\n",
    "        param = 'V{}'.format(i)\n",
    "        w.append(trace_advi[param].mean())\n",
    "      w.append(trace_advi['Amount'].mean())\n",
    "      b = trace_advi['Intercept'].mean()\n",
    "\n",
    "      a, p, r, f = compute_metrics(w,b,X_test,y_test)\n",
    "      accuracy.append(a)\n",
    "      precision.append(p)\n",
    "      recall.append(r)\n",
    "      F1.append(f)\n",
    "        \n",
    "    results = {'iters': iters, 'tol': 0.0001, 'accuracy': accuracy, 'precision': precision, \n",
    "               'recall': recall, 'F1': F1, 'times': times} \n",
    "    \n",
    "    with open('results/pymc3/{}_{}.pkl'.format(filename, seed), 'wb') as f:\n",
    "      pickle.dump(results, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pymc3_vi(df, 'vi_credit', seeds=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015\n",
    "\n",
    "[2] Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
